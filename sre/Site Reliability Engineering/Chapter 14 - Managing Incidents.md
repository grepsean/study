# Managing Incidents

효율적인 장애 관리의 핵심은 빠르게 normal 상태로 복구하는 것이다. 만약 potential 장애 처리에 대해 미리 대응 메뉴얼을 만들어 두지 않았다면, 원칙적인 장애 관리는 쓸모없어질 것이다.

이 챕터에서는 ad hoc한 장애 관례를 인해서 통제할 수 없는 장애가 발생한 것에 대해서 살펴볼 것이다. 이러한 장애를 잘 관리할 수 있는 방법을 살펴볼 것이다.

# Unmanaged Incidents
Mary라는 on-call 엔지니어 입장이 되어보자. 묙요일 오후 2시가 되면 노티(pager) 폭탄을 맞게 된다. Black-box 모니터링을 통해서 전체 데이터 센터에서 어느 트래픽에 대해서 장애가 발생을 인지했다. 한숨을 쉬는 것을 시작으로 커피를 손에서 내려놓고 복구를 시작한다. 작업을 몇분 진행하는 동안 또 다른 장애 알람이 들어온다. 그리고 5개의 데이터센터중 3개에서 다운된다. 상황은 더 악화되어 살아 있는 데이터센터는 자신의 capa보다 많은 트래픽을 처리하면서 과부하가 발생하고 결국 정상적인 서비스가 불가능해진다. 

로그를 처다보고 있지만 영원히 끝나지 않을 정도로 쏟아진다. 수천 라인의 로그 속에서 최근에 업데이트한 모듈에 문제가 있다는 힌트를 얻었고 이전 릴리즈로 롤백을 하기로 결정한다. 그리곤 롤백도 도움이 되지 않는다는것을 알게되고 대부분의 코드를 작성한 Josephine을 호출한다. 그녀의 timezone에서는 새벽 3:30이라는것을 상기시키며, 그녀는 눈을 비비며 로그를 같이 살펴보기로 한다. 동료인 Sabrina, Robin도 같이 조금 살펴보겠다고 한다.(Just looking)

그리고 boss가 화가나서 왜 "total meltdown of this business-critical service."에 대해서 보고 받지 못했는지 이유를 요구한다. 동시에 부사장에게도 "How could this possibl have happened"를 반복적으로 불평하며 ETA를 요구한다. VPs call 중 이전 엔지니어링 경험으로 "Increase the page size!"라는 관련은 없어보이지만 거부할 수 없는 요청을 받는다. 

시간이 지나 나머지 두 데이터 센터도 다운되었다. 잠에서 덜깬 Josephoine은 Mary 모르게 Macolm을 호출한다. 
Macolm은 CPU affinity에 대해서 의심을 했으며, 자신이 서버 프로세스에 대해서 최적화할 수 있고 심플한 변경을 프로덕션에 배포만 하면 된다고 확신했다. 그리고 그렇게 했다. 
몇초 후 서버가 재시작되어 변경사항이 반영되었지만 결국 죽었다.


# The Anatomy of an Unmanaged Incident
위의 시나리오 처럼 모두가 자기 일을 했지만 상황은 왜 나빠졌을까? 몇가지 위험 요소가 결국 통제 불능을 야기 시켰다.

## Sharp Focus on the Technical Problem
보통 Mary처럼 technical 역량를 가진 사람들을 고용한다. 그녀가 문제를 해결하기 위해서 운영적인 변경을 하는데 바빴다는 것은 전혀 놀랍지 않은 일이다. 
그리고 그녀는 technical task가 너무 많기 때문에 이러한 문제를 어떻게 해결할지 빅픽처를 생각할 위치의 사람은 아니다. 

## Poor Communication
비슷한 이유로 Mary는 명확하게 커뮤니케이션할 수 없을 정도로 바빴다. 동료들이 어떤 액션을 취했는지 누구도 알지 못했다. 비즈니스 리더는 화가 났고, 고객은 짜증이 났다. 그리고 같이 디버깅하고 복구하는데 다른 엔지니어들의 도움이 효율적으로 활용되지 않았다.

## Freelancing
Malcolm은 자신의 최선의 의도로 시스템 변경을 했지만, 트러블슈팅의 메인 담당자인 메리와 조차 협업을 이끌지 못했다. 그의 변경은 결국 상황을 더 악화시켰다.



# Elements of Incident Management Process
장애 관리의 skill과 practice는 각 개인의 열정적인 노력을 이어지게 하도록 한다. 구글의 장애 관리 시스템은 [Incident Command System] 이라는 것을 기반으로 한다. 
잘 디자인된 장애 관리 프로세스는 아래와 같은 피쳐를 가진다.

## Recursive Separation of Responsibilities
장에와 관련된 모든 사람들은 자신의 role을 명확히 알고, 다른 사람의 role을 침범하지 않아야한다. 
책임을 명확히 분리하면 그들의 동료의 second-guess가 필요하지 않으므로 각 개인은 더 자율성을 가지게 된다. 

어떤 사람의 로드가 과부화되면, 그 사람은 더 많은 사람이 필요하다고 리더에게 요청해야하고, 그 일을 다른 사람에게 위임해야 하는데 이 일로 인해 또 다른 sub 장애가 발생할 수 있다. 또는 


### Incident Command
장애 관리자(commander)은 장애에 대한 high level 상태를 관리한다. 장애 대응을 위한 task force를 구성하고, 필요와 우선 순위에 따라 책임을 할당한다. 사실상 표준으로 관리자는 delagated되지 않은 모든 포지션을 담당한다. 가능하다면 Ops팀이 효율적으로 동작하게 하지 막는 장벽을 없앨 수 있다.

### Operational Work
Ops의 리더는 장애 관리자와 협업하여 operational tools를 적용하여 장애 대응을 할 수 있다. 운영팀은 장애동안 시스템을 수정할 수 있는 유일한 그룹이어야 한다. 

### Communication
이 사람은 장애 대응 task force의 첫번째 컨텍 포인트이다. 그들의 권한은 장애 대응팀과 이해 관계자에게 이슈에 대한 주기적은 업데이트를 해주는 것이다. (주로 이메일을 통해) 그리고 장애 보고서를 정확하고 최신으로 업데이트하는 일로도 확장될 수 있다.

### Planning
Planning role은 longer-term 이슈를 처리하므로써 Ops팀을 서포트한다. 예를 들면, 버그를 올리고, 저녁 식사 주문하고, handoff를 arraging하고, 정상 상태와 비교에 어떻게 다른지 tracking해서 장애 복구되면 revert될 수 있게 한다.


## A Recognized Command Post
관련된 그룹들은 장애 관리자와 소통할 수 있는 곳을 알고 있어야한다. 많은 상황에서, 장애 TF 멤버들은 "War Room"이라는 곳에 위치해 있다. 다른 팀들은 각자의 선호하는 곳에 위치해있을 것이고 장애 업데이트 메일/공지을 주시하고 있을 것이다.

구글은 장애 대응에 IRC를 사용한다. IRC는 매우 reliable하고, 어떤 이벤트의 커뮤니케이션 로그로 활용할 수 있다. 또한 장애 관련 트래픽을 로깅(postmorterm에 유용함)할 수 있는 봇을 만들고 로그 이벤트를 채널로 alert할 수 있다.
IRC는 또한 지역적으로 분산되어 있는 팀이 협업하기에 유용하다.

## Live Incident State Document
장애 관리자의 가장 중요한 책임은 장애 보고서를 최신으로 유지하는 것이다. 이 문서는 wiki에 있을 수도 있지만, 여러명이 동시에 편진할 수 있어야 한다. 팀의 대부분은 Google Docs을 이용하고, Google Docs SRE는 Google Sites를 이용한다. 

장애 문서 예제 [Example Incident State Document](https://sre.google/sre-book/incident-document/)를 살펴보면, 좀 지저분할 수 있지만 기능적이어야 한다. 
Template을 이용하면 좀더 이러한 문서를 쉽게 만들어 낼 수 있고, 가장 중요한 정보를 최상단에 위치시켜 더 유용하게 해준다. 
이러한 문서는 postmortem analysis이나 메타 분석위해서 유지하자.


## Clear, Live Handoff
working day가 끝나면 다음 장애 관리자에게 명확하게 인계하는것은 필수적이다. 만약 다른 위치에 있는 관리자에게 인계할때는, phone이나 video call을 통해서 새로운 장애 관리자를 간단하고 안전하게 변경할 수 있다. 새로운 장애 관리자가 통보되면, 이전 관리자는 "당신은 이제 X맨입니다"라고 명확하게 인계를 마무리해야한다. 그리고 인수인계에 대한 응답을 받을때 까지 call에서 나가면 안된다. 인수인계가 마무리되면, 이제 누가 장애 관리에 대해 주도하고 있는지 명확하게 알려야한다.


# A Managed Incident




















